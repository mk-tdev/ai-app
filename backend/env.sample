# Provider Selection
# Options: llamacpp, ollama, huggingface
PROVIDER_TYPE=llamacpp

# LlamaCPP Settings (for GGUF models)
MODEL_PATH=./models/mistral-7b-instruct-v0.2.Q3_K_M.gguf
N_CTX=4096
N_GPU_LAYERS=0
TEMPERATURE=0.7
VERBOSE_LLM=false

# Ollama Settings
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# HuggingFace Settings
HF_MODEL_NAME=gpt2
# HF_API_TOKEN=your_token_here  # Optional: for private models